# Классификатор спам-сообщений (SMS Spam)
Модель машинного обучения для бинарной классификации SMS-сообщений на спам и не-спам (ham). Проект включает в себя полный цикл: от исследования данных (EDA) до обучения модели и оценки её эффективности.

## Запуск

### В Google Colab (Рекомендуется)

Самый простой способ открыть и запустить проект — использовать Google Colab. Это не требует установки ПО на ваш компьютер:

1.  **Откройте ноутбук в Colab:** Нажмите на кнопку **"Open in Colab"** вверху этого файла.
2.  **Подключите среду выполнения:** В Colab нажмите `Runtime` → `Run all` для выполнения всех ячеек ноутбука. Colab автоматически предоставит необходимое вычислительное окружение.

### Локальный запуск

Если вы хотите запустить проект на своем компьютере, выполните следующие шаги:

#### 1. Клонируйте репозиторий
```bash
git clone https://github.com/BRSHD/spam-classifier.git
cd spam-classifier
```

#### 2. (Опционально) Создайте и активируйте виртуальное окружение
```bash
python -m venv venv
# Для Windows:
venv\Scripts\activate
# Для Linux/macOS:
source venv/bin/activate
```

#### 3. Установите зависимости

```bash
pip install -r requirements.txt
```

#### 4. Запустите Jupyter Notebook

```bash
jupyter notebook spam_classifier.ipynb
```

## Данные
Используется открытый датасет [SMS Spam Collection](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset) с Kaggle.

**Размер:** 5572 сообщения

**Классы**:

-***Ham (Не спам):*** 4825 сообщений (86.6%)

-***Spam (Спам):*** 747 сообщений (13.4%)

**Признаки**: label (метка: spam/ham), text (текст сообщения).

## Технологии и библиотеки
**Язык:** Python 3.12.11

**Анализ данных:** Pandas, NumPy

**Визуализация:** Matplotlib, Seaborn

**Машинное обучение:** Scikit-learn

**Обработка текста:** NLTK, re (регулярные выражения)

**Среда:** Google Colab

## Основные этапы проекта
Загрузка и исследование данных (EDA):

-Анализ распределения классов (выявлен сильный дисбаланс).

-Визуализация данных (круговые диаграммы, гистограммы, boxplot).

-Анализ длины сообщений в разрезе классов.

Предобработка текста:

-Приведение к нижнему регистру.

-Удаление пунктуации и стоп-слов.

-Лемматизация.

Векторизация текста:

-Преобразование текстов в числовые векторы с помощью TfidfVectorizer.

Обучение моделей:

-Тестирование нескольких алгоритмов: Naive Bayes (MultinomialNB), Логистическая регрессия (Logistic Regression).

Оценка моделей:
-Анализ метрик: accuracy, precision, recall, F1-score, ROC-AUC, PR-AUC на тестовой выборке.

## Результаты
Модель логистической регрессии показала наилучшие результаты.

| Модель                  | Accuracy | Precision | Recall  | F1-Score | ROC-AUC | PR-AUC  |
| :---------------------- | :------- | :-------- | :------ | :------- | :------ | :------ |
| Logistic Regression | 0.9794 | 0.9922  | 0.8523 | 0.9170 | 0.9975 | 0.9861 |
| Naive Bayes             | 0.9722   | 0.9917      | 0.7987   | 0.8848    | 0.9858   | 0.9613   |

## Лицензия
Этот проект распространяется под лицензией MIT. Подробнее см. в файле LICENSE.
